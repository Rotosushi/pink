we will allow inner names to shadow outer names, and we will let this happen
naturally by the fact that structures that introduce new scopes will do so
by literally introducing a new symbol-table, wherein local names will be bound.

this means that the simple form of lookup will find the inner binding before
it would search the outer symbol table.

okay, so we can also take the easy road right here
and disallow variable shadowing. and report it as a
syntax error

if we combine this with namespaces, this allows for the lookup
of so called fully qualified names, this would allow the programmer to be
explicit when they access a shadowed binding. This would allow a programmer to
explicitly capture variables from an outer scope. These would be captured
according to the lambda rules that were developed for handling this exact issue.


so, to that effect what should the namespace rules be?

well, the most straightforward one would be to associate each construct
which defines a scope with a new symbol table, then each new symbol table
also defines a new namespace. This would mean that each symbol table could be
unambiguously referenced textually through the program. However, some
complixities are underneath such a solution. in the case of the global
namespace, and the namespaces that get associated with formal functions
this approach works great, because we will have a unique string able to be
associated with each namespace. This same logic would carry over to classes
and to modules if the language gets any.
However what about name conflicts between anonymous
scoping constructs, like while and for loops, if conditionals and lambdas? These
constructs are still able to create declarations, and those declarations
could possibly shadow outer declarations; and due to their anonymous nature
there is no unique string that can be immediately associated with their
scopes. Thus there would be no way of directly accessing a variable that
was shadowed in an outer scope twice or more.

def f (...)
{
    x := ...;

    x; # This reference to x is easy to disambiguate

    if (...)
    {
        x := ...; # shadow declaration

        x; # this reference to x means the new declaration
        f::x;   # this reference explicitly means the
                # outer shadowed over declaration, meaning
                # the namespaces construct provides value in
                # this case.

        while (...)
        {
            x := ...; # second shadow declaration

            x; # this reference to x means the new declaration

            f::x;   # this reference explicitly means the outermost shadowed
                    # variable, and there is now no way of reaching the inner
                    # shadow variable. and there is no straightforward way
                    # of associating anonymous scopes with a label such that
                    # a programmer can easily disambiguate them. Scopes Sets
                    # also do not help in this circumstance.
        }

        x;  # this reference means the first shadow, as the second shadow's
            # lifetime ended at the above closing curly brace.
    }

    x;  # This reference means the first declaration as the first shadows
        # lifetime ended at the above curly brace
}

in c/c++ this situation is simply allowed, and the above scenario can be
written down and will have the semantics mentioned above.
additionally, scope-sets as implemented earlier
https://www.cs.utah.edu/plt/scope-sets/
do not solve this problem of disambiguation in this specific scenario.
in fact, scope-sets don't do anything materially different than having
each new scoping construct introduce it's own symbol table of bindings.
As the largest match for a given name is always going to be an inner binding.
because inner declarations will have the largest scope set, and so inner
references will refer to inner bindings. The behavior is entirely correct,
and redundant unless we need to add hygienic macros. (which are really cool
and totally a feature I am thinking about adding, but also, getting to a
working first version is the goal right now, then neat stuff can be built
on top of the kernel.)

so, constructs that introduce a new scope along with a mandatory name
will introduce a new namespace. Which is all of, none of the constructs
in the first version, the only places where this would happen is formal
functions, modules, and if they are implemented classes.

an overloading mechanism which allowed for a solution to the
expression problem would require that calls to overloaded methods go
through a dynamic table. This is the only way I can see a way for a
compiled function call site to potentially call a different method depending
upon what modules have been included. and for our current language,
which is statically typed, to call a new function would mean that the
function call site was suddenly working with different types of object.
this cannot happen in a compiled statically typed procedure. We would have to
be talking about a polymorphic function to be talking about a function
which can take in different types per call site. And if we were talking about
that we would be talking about a situation which was occurring during compilation.
not after, and thus overloading is not a solution to the expression problem.
If we kept the full compiler around in a compiled program, then we could imagine
constructing the required statically typed functions as the dynamic libraries
were loaded onto the program, and new call sites were added to already written
polymorphic functions. However, this breaks with the original goal of not
putting a full compiler into every compiled program, because if we did that
then you should just use a lisp dialect.



And this isn't a perfect solution.
it does cover the case where an inner scope needs to access a name declared
in an outer scope. Which solves part of a problem with the language
as currently defined. However, it also solve the part of the problem needed
for disambiguating between global identifiers with the same names as each other.
They will mesh well when the langauge is extended with modules,
which are an essential part of program composition.




So, thinking it through even more,
the lambda construct itself needs to allocate memory in order to properly
do it's work. since we are talking about procedures which can be constructed
during runtime. In order to not create an invisible dependency on the standard
memory allocator, we could enforce that lambdas when defined must specify
their allocator.
This comes from zig, because that language is a huge inspiration.
this changes their syntax to something not yet decided.
Any type that performs dynamic allocation must do so through an allocator.
this is uniformly true across all programming languages. In C/C++ this
is done manually through the languages kernel. (malloc/free, new/delete)
in interpreted languages this is done through their allocation mechanism
and then the deallocation is handled by the system. If we want the standard
feature of a runtime procedure instance to be supported by the lanugage,
and we want as little runtime overhead as possible for using such a construct.


I just want to program in zig apparently...
it lines up with every choice i wanted to make with c, and more. so like...

anyways...

a lambda could have syntax which required that the first argument always be
the allocator to use when allocating, but that might be confusing, so a postfix
property,
\x, y => @allocator(...) { }

would make it more clear what was going on and when.

then, assigning this lambda object to a name works just like regular
dynamic memory in zig. except it is a callable object, though it does
have a unique call strategy compared to other functions, and as such
would need to have a subtly different type within the context of the language.
which might itself be a point of confusion. The other neat
thing is that this lambda object would play really well with ad-hoc polymorphism
(zig anytype.)
however, both combined seems to imply runtime type disambiguation.
