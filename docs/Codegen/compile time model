so, okay, we want to compile programs
written in pink to compile to machine
code. not efficiently at first, but
we aren't aiming for inefficient either.
to this end we are targeting llvm as our
middle end. i really like what llvm is
doing, despite the fact that it becomes
more natural to interface in c++ again.

so, this language is small for languages,
and this document is going to serve as the
language standard of sorts for now.

we might as well start at the beginning.

the EBNFish grammar right now:

// all operations have a lower precedence than applications.
// so F x y + G a b is always parsed as the addition of
// the result of two applications. (F x y) + (G a b)

affix := application
       | application operator affix // binops are parsed separately by a traditional binop precedence parser.
       | application "<-" affix

application := primary
             | primary application // space separated sequences of terms are applications.

primary := identifier (':' type? '=' affix)? // rn this is not const, and there is not a notion of const
         | "nil"   // nil and false are basically the same, except nil is the unit type.
         | integer
         | "true"
         | "false"
         | "\\" identifier ":" type "=>" affix
         | "if" affix "then" affix "else" affix
         | "while" affix "do" affix
         | operator primary
         | "(" affix ")"

type := "Nil"
      | "Int"
      | "Bool"
      | type "->" type // a function type is written as a composite type
      // new types will be defined alongside procedures to work with the type.
      // mut (type)? // a mutable type, if the type is elided in the bind expr, we infer the type.
      // type'*' // a pointer type
      // [type 'x' affix] // an array type
      // {(identifier : type ('=' affix)? (',' identifier : type ('=' affix)?)*)?} // a labeled anon struct type
      // { ( type ( '=' affix )? ( ',' type ( '=' affix )? )* )? } // an unlabeled anon struct type
      // the equals binds the structs cell to an initialization expression whose type matches
      // the cells type. (i.e. literals, constant expressions, expressions dependent on earlier bindings etc.)
      // '{}' is equivalent to saying



// if things go well and we get to pattern
// matching, '_' will be the text for the
// empty term/match/binding
identifier := [a-zA-Z_][a-zA-Z0-9_]

integer := [0-9]+


the type system is also fairly standard.

the type of nil is Nil (in llvm i1)
the type of true and false is Bool (in llvm i1)
the type of integers is Int (in llvm i64)


the type of an if expression is only valid
if it's condition expression has type Bool
and the type of both the alternate expressions
have the same type. then the type of the
if expression is the type of the alternate
expressions.


the type of a while expression is only valid
if the type of it's condition is Bool, and
it's body has some type, then it's type is
Nil. (maybe instead it's optional<T> where
T is the type of the body. and we get a nil
optional when we evaluate the conditional the
first time, and it turns false. that is
in the event that we never run the body, and
thus never initialize the result type.
an interesting thing to note is that the
do-while structure of a loop doesn't have this
problem, as it's body always runs at least once.)

the type of a binop expression is the
result type of the binop elimination procedure
which takes the types of the left and right
terms.

the type of a unop expression is the
result type of the unop elimination procedure
which takes the type of the right term.

the type of a procedure is the type of it's arguments,
appended to the type of it's body. (we consider terms
where the argument appears within the body to have
the type of the argument.) the arguments annotation is
explicit and required of the name.

the type of an application is the type resulting from
applying each of the types of the actual arguments
to the type of each of the formal arguments.
(a procedure which formally takes two integers can
 be applied by supplying two integers or terms with integer type.
 a procedure which formally takes two integers can
 be partially applied by supplying one or zero integers and
 then binding that temporary or using it in a larger expression.
 this results in the allocation/creation of a closure which
 represents that procedure in a local/expression context.)
the result of an application is either a function type
or a non function type object. but it's always knowable
from the static type of the application and the static type of
the callee.

---------------------------------------------------------------------

the local storage of a closure is an opaque ptr to dynamic memory, but it's type is
fully deterministic with respect to the structure of the program.
you have to define a procedure with a definite number of arguments
and apply it with a definite number of arguments, since these
are two definite numbers we know that we can do a three way comparison
on the number and type of the arguments being supplied at every point
at compile time. if given more than we expect, that's still an error,
if given just the right number and type, that's a regular application.
if given less than, only then do we build a closure. and since we
built it from a finite type, and we were given a finite number
of arguments, the expected number of arguments needed to build a
proper application from a closure is also definite at compile time. the expected
and supplied type of each of the arguments in any given application term
are known as well. the number of times you can bind a new argument to
the closure and not have it be a valid application is a finite knowable number.

in spite of the fact that we need to represent closures as opaque
pointers, the number and type of the argument list within a function is
still static. this means that we can rely on the fact that each of
the closed over values are of the right type. it had to be to build it.
to even properly type the application which defined the closure.

the only thing we cannot rely on, that we normally can with C style
procedures as values is preciesly how many arguments the underlying
closure has bound, before we get to the 'rest' of the
procedures type which is the type of the closure, and the type of
a formal argument binding a function object.

since a closure with the presented correct type could be representing
a call to a procedure accepting more arguments than the type of the binding
closures must be allocated like C++ vectors. they are, in essence
dynamically sized. what is constant about any given closure that
could be bound to the arguments type is that is takes the
argument type more arguments, to produce a result value of the
argument types return value. that is, the rest of it's application
has the correct type to be applied by the procedure accepting
the type as argument.

we also know a maximum upper bound on the size of any given closure
at any given time. it is the size of the argument list as values in
an anon struct, minus the last argument. (because if you supply that
we apply the procedure instead of building another closure.)


normally we consider simply typed lambda calculus procedures to be curryed
which means that formally, they only take a single argument.
however if the body of the lambda is itself immediately another lambda
then an application of that lambda could supply a sequence of names
which gets consumed by the rules of the calculus
into what is essentially a multiple argument application. (each argument
is bound one at a time) the only real difference is how you write down
the argument list of the lambda itself. formally

\x:Int, y:Int, z:Int => x + y + z
is
\x:Int => \y:Int => \z:Int => x + y + z

the key insight that i am leveraging is that the procedure
body is constant for any given value of type Int that is bound
to each of the arguments plus this notion of currying, to
say that the C style procedure

int fn(int x, int y, int z)
{
return x + y + z;
}

is an equivalent definition as well.

 the big difference is the lambda calculus's
ability to treat functions in a value sense. in terms of the grammar.

saying terms like:



multiply := \a:Int, b:Int => a * b

local_fn := multiply

apply := \f:Int->Int->Int, x:Int, y:Int => f x y

apply (\x:Int, y:Int=>x + y) 3 4

apply multiply 30 13


aux := \a:Int, b:Int, x:Int, y:Int=> a * x + b * y

add := apply aux 1 1

sub := apply aux 1 -1

double := apply aux 0 2 0

triple := apply aux 0 3 0


aux has type

Int -> Int -> Int -> Int -> Int

(which is a lot to type out by hand to be fair
all 5 elements)

add has the familiar type

Int -> Int -> Int

(which you will notice is 5 - 2 = 3 elements long)

sub has the same type as add.

double and triple however have a type of

Int -> Int

which is 5 - 3 = 2 elements long.
which is the smallest function type.


all of the closures defined above are over the same procedure,
the only difference between the data they need to store is
which particular integer is being applied.

so, my question is do we allocate the same underlying type
for each procedure. or do we allocate only enough to hold
exactly which arguments we have bound?
well, it's simpler from an implementation perspective
to only have one allocation type per procedure being closed
instead of the number of arguments minus one types per
procedure.

so, for a given procedure, the closure object is
{fn-ptr, {closed-arg0, ..., closed-argn}}
where n is the number of arguments in the functions list minus
one.

so for aux, the closure type will, at a minimum, be

{aux, {i64, i64, i64}}

however. this still leaves us with a problem with respect to
calling a passed closure. because we expect a closure whose
presented function type is correct for the argument binding,
but as we saw above the same closure storage type can represent
different function types, and at the same time, different
base procedures could reduce to the same presented type, despite
the fact that the function definitions themselves could have
different types. they just have to share the same type
past a certain number of arguments in their list.

all of this means that we cannot pass the closure objects directly,
and we cannot store them locally. just like with how we don't
store a vectors array allocation directly, we locally store a
reference to a vector locally. because despite both closure objects
sharing a type, they have distinct storage characteristics.
this is similar to how two different vectors of ints can have distinct sizes.
fundamentally this is because we are using a proxy for the
procedure instead of the procedure itself, and the storage
characteristics for this proxy object are what we are thinking about.
this has disconnected the type of the procedure from the storage
characteristics of that type which is representing the procedure
locally. which is very much unlike what we
know about our other primitive types. Int has a definite size
prior to the beginning of the program. and even other composite
types. typedef'ed arrays and structs sizes are runtime constants.
since the closure allocation itself can not be stored
locally, because they violate the idea that we can process any value
of some type with the same allocation space for any given value of said type,
what can we store locally? a pointer to the closure
allocation, and since we cannot rely on the type we are pointing to,
we have to pass them as opaque pointers to dynamic memory.
we have to rely on something else, this is what we have to define
ourselves to reach the correct semantics.
we also have to store a structure that can be used to build
an argument list at runtime from a passed closure object,
and hence, call the underlying procedure. we need to process
the arguments from the closure, the arguments from the application
term, and turn them into either a closure or a procedure call.

this reference to the closure allocation is then what we consider
storing locally or passing as an argument or return value.
we wrap it in a structure to allow for some metadata to be added later.
this then allows us to pass closures through procedures defined
in a more C style. in the same way we can pass strings into
procedures in C++, but what we are passing is a reference to
the C style array allocation of characters. (this is consistently
combined with an implicit copy to achieve by-value semantics.)

however, if the function is static for the lifetime of the program
and the only difference is the values. then storing the partial
application of a procedure, is equivalent to storing the same function pointer
plus the value being bound right? which particular value is what is
unique from call to call of the same procedure. certain other features
can rub up against this particular assumption, particularly when thinking
about shared data. however, to get something working we must be daring.


strings representing names within the program are Interned. this
allows programmers to treat the address of the name, as if it were
a unique value which could be equality compare to other interned
strings and you could tell if the two names are the same.
because they have the same address, which means they quite
literally refer to the same value. the same exact cell in memory
even.
the same could be said of static (C) procedures, the address of the
procedure is the same no matter which values we supply as arguments.
the function begins evaluation of the same block of code each time,
and each block of code is static each time it is run, we are talking
about essentially a segment of memory (a text file if you want) that
is being treated as a sequence of instructions by the CPU.

when we 'call' a procedure, the entire calling sequence is an abstraction
that the CPU does not directly support, the most the CPU does is
manage your function's frame pointer. managing the arguments is
the task of the compiler. all we do past arguments to 'call' is jump to the
first instruction of the definition of the function.
if the function is defined to take an integer or three as arguments,
then it will always and forever exist in the text file, ready to
accept an integer or three evaluate and return.

the cells of the procedures body are static during the runtime of the program,
if we define a procedure taking a composite value, then it will
at any time accept a value of that composite type.

if we imagine a procedure (f) that takes another procedure (g) as argument,
the definition of f contains an application of g.
since the application is specified statically by the programmer, and
every term of the application has a static type, and we know we strictly
evaluate application terms. we can know that we are either
emitting a call of a procedure at this application term, or we
are building a closure at this application term. this choice is
reflected in the result type of the application. the type is
either a function type in the latter case,
or it is a primitive type in the former case.

so the problem is can we can emit a static application sequence
to handle any passed closure that presents the same function type
the procedure arguments function type as it's current calling signature.

to say that another way the argument enforces some
concrete procedure type that any passed closure must conform to, however
with our definition of closures being what it is, the underlying
procedure could have bound any (N) number of arguments before
it's type was refined to the concrete type accepted by the
argument. this means that the block of code which builds applications
needs to build them against N arguments being given by the closure
itself.

we keep the same assumption that if the arguments
concrete type expects (Y) arguments to apply the function,
then we know that (N + Y) arguments is the correct number of
arguments needed to build an application of the underlying procedure.

if the actual provided number of arguments (X) is bigger, equal to, or
smaller than (Y) we will know that when we parse the application term.

and since the types of the underlying procedures are always static,
of length (M) when we make the choice at this application block,
to build either a closure or an application of the function pointer
within the closure this choice will be the correct choice for any closure
that was bound to the given function argument type. because the underlying
procedure must have an argument list that is either equal to or
larger than the function type specified by the argument.
this is the only way that a closure would have been constructed which
would present a function type that matched the argument list type,
was if the underlying function type contained as it's argument list type
the same matching 'rest' of the function type.

and, since the closure itself was built from another application term somewhere
the types of any closure values we find, and the order in which we find them
are correct for the given function type.
they had to be, in order to build the closure around those values.

so, i think we could build an implementation that when we were building
an application we simply built a single
local alloca for all the argument values, memcpy'd in the closed over values,
then immediately following that within the alloca we memcpy'd the actual arguments
from the application term, in the end building up what is a single struct
of all of the arguments to the function. then we pass this single struct in
via a single pointer, that then the function bitcasts to a pointer to a
struct of it's arguments, then we should be able to use GEPs to get
our argument values. (the implemented procedure would be marked as by-ref in this
scheme, because we just made a bunch of local copies manually, i.e. by-value)
the return value is going to be an arugment so we can support multiple
return values via structs. the result of the application in our code
is then to be a reference to the result value allocation.


building another closure means building a heap allocation where
we copy over the same function pointer, but we also copy in
the older closure over values and the newer closed over values.
although, if we were talking about a closure that always has
enough room for all of it's possible values, we could literally
just copy in the new arguments into their positions within the
closure we were just passed.


we can treat the pointer of a function in the same way,
it's only the same procedure if it is the same address, because
that is where that procedure is stored. but more than equality
comparison, the pointer to the procedure stored within the
closure has a type. we can consider it a local version of the
procedure in the same way we consider the interned string a local
copy, we can unwrap it into the correct thing. and like with
all functions we unwrap it with application.
if we can get the static type of the closure
to the dynamic call point, can we construct the call then?
or do we only ever need the individual types at each step?
or do we only need the sizes and we simply cast inside the procedure?

----------------------------------------------------------------------
with C there is this funny sense of errors, and it is so within assembly
programming also. and it is this sense that there is some set of
errors from the strictly theoretical perspective that are simply
allowed to happen because it would be much more expensive otherwise.
errors like int/float overflow, if you don't check the overflow bit
you wont know it happened, (i think the some CPU's also trap and run
an interrupt? i need to do more research here) but my logic is,
the runtime of a c program doesn't trap when you compute an out
of bounds address. the computation of the index and the indexing
are separated by time. what does crash the program is dereferencing
an out of bounds address. this means that instead of inserting checks
on all of the math that the program does, it only emits checks
on the memory access that is does.
why can we ignore one class of error and only have the other?
well, this is a matter of opinion truly, because there are languages
which check all bounds computations, and don't delegate that error
to the same segmentation fault error.
the basic problem of overloading segmentation fault with so many
different errors from so many different basic syntactic forms
is that the presentation of the segmentation fault to the programmer
essentially destroys the information of what caused the segmentation
fault in the fist place.

-----------------------------------------------------------------

so, the compile time has to contend with
a few major things, constants/literals
variables, primitive operators, two
control primitives and lambdas/procedures.

we consider every identifier to label storage
cells. each storage cell has a type, and the type
determines to layout of the data held within the
cell, if it is a primitive type, the cell is
also accompanied by a set of primitive operators
which provide a base set of actions that can be
performed upon cells of said type.
functions generalize the idea of abstracting over
language expressions, such that
the same procedure can accept any particular
instance of a cell of a type, instead of the particular
cell being baked into the specification of the expression.
the procedure performs the same
set of instructions upon that cell. since the procedure
accepts values, consumes them and then produces a single
cell as it's result, we want the memory which the
procedure is performing it's action upon to be somewhat
flexible with respect to the programmers intention.
this is why by-value was chosen, simply because upon
by-value we can easily have the programmer specify
reference semantics exactly where they need it, and
under the hood the compiler can perform all sorts of
copy elision to make the by-value semantics fast.
(because we are using LLVM which already optimizes by-value
procedures in it's day to day.)
we still have the flexibility to pass a reference by value,
which allows the programmer to point the reference to either
stack or heap memory and the callee simply unwraps performs the
action and returns, this allows the same procedure body to
perform upon both stack and heap memory cells. because the reference
it takes by argument is allowed to point to the stack or the heap.
we shouldn't allow pointers to be returned from procedures
unless they point to malloced memory or to global memory.
stack pointers are valid as arguments, and as intermediate
results before their lifetime ends. but returning pointers
to the stack is almost never valid semantics, it is really
only ever valid if the pointer being returned was one that was
passed, and that one that was passed is not returned out of
it's defining scope. if it was passed it's lifetime must extend beyond
the lifetime of the procedure, because it existed prior to this
function being called, which means it must be defined outside
of the procedure accepting it as an argument.

for version one, we are requiring explicit type annotations on all
arguments. we allow the definition of a variable to infer it's
type based upon it's initialization expression; and are going to
provide an optional type annotation of the term for explicitness.

identifier ":" type? "=" affix

this allows bind expressions to optionally specify the type, which
causes the compiler to ensure that the initialization expression has
the same type as the annotation expression.

so, we allow three primitive types in our first version,
and one composite type. the primitive types are
Nil, Int, and Bool. (where Int means i64) ((and Integer
will be the type of an infinite precision signed integer.))
the composite type is the procedure type, which is composed
of it's argument type and it's return type.

we have a few basic operations that are provided by the language
semantics. namely assignment, binding, and equality comparison for all
primitive types,
the four arithmetic primitives for Ints, and the
three Boolean primitives for Bool's. Nil has no basic operations.

lastly we have a few basic expressions which are defined, namely
the 'if' * 'then' * 'else' * term, which allows choice of
evaluation, and the "while" * "do" * term, which allows repetition
of evaluation.







so, since we purport to be a small footprint
language like C, why did we pick a high level
of abstraction language like the lambda calculus?
well, because I want the conception of functions
to be as complete as possible for a low-ish level
programming language. certainly I am going to have
more of a runtime than C. But no larger than a
runtime in C++ imo. and i think with a more functional
starting point, we will shore up some problems with
C, rather than just adding more and not really fixing
things, cough cough C++.


so anyways, what do i mean, more of a runtime?

well, C lacks a complete conception of functions,
this isn't really debatable, they are monotonic.
we cannot 'pass' procedures, nor may we return
them, or store them as values. their names may not be overloaded, nor
can we define new procedures polymorphically.
to my mind, C++ proves we can add these things
with enough effort and ingenuity, and looking
at how functional languages have been implemented
in the past, i think we can have a good execution model
with a balance between speed and power.

We are borrowing a lot of ideas which originated in
(S)ML, LISP, and Scheme. which are the other languages
first based upon the lambda calculus. now,
many of these languages are 'interpreted' at least
at first, nowadays you can find many optimizing
compilers for LISP and Scheme dialects. and as such
many techniques have already been thought of for
implementing the particular semantics implied by
the lambda calculus.

so, the main problems with the lambda calculus from
the perspective of C arises from three use cases of
procedures in the lambda calculus which are not directly supported in C.

- passing procedures as values, either downwards through
arguments/parameters, horizontally with local storage
of lambdas/locally defined procedures, or upwards through return values.

- closures a.k.a. partial application of lambda terms


- the use of assignment in the presence of popular
functions-as-values implementations, specifically
closure implementation patterns
which usually copy and restore the stack which
by definition copies the variable into potentially
arbitrarily many positions in memory, which makes
updating across all these positions difficult.


the first and most obvious strategy is to fully disconnect
the storage of procedure data from a stack allocation
strategy altogether. which simple, understandable, and
very well-trodden, this strategy has one major downside.
now, we require the use of a garbage collector, a data
structure which has a bad habit of inserting a few
cache-misses into every procedure call. this is
completely unacceptable from multiple angles in an
embedded environment.
1) the garbage collector is both a source of
  unknown time delays and a lot of memory overhead
  in bookkeeping, this is too much time and space
  overhead during the regular operation of a program
  to write something as potentially low-level as an
  operating system, or a hardware driver.
  with C, you can write hardware emulating software
  through the use of interrupts and clever usage of
  inline assembly. this kind of timing consistency
  is not possible in a garbage collected environment.
2) given that all procedures are dynamically allocated,
    every possible procedure call is hindered, just to
    support a language feature that many programs will
    never use. coroutines are very useful, but they
    are also rarely used in day to day code, and I actually
    agree with C++'s motto of "don't pay for what you
    don't use." here. so forcing programs to pay for
    what they don't use is not good.

so, to skip to something that I think has a good shot
of being fast, and still supporting advanced programming
techniques, is a hybrid stack/heap approach.

so, thinking about the first issue, closures:

we only use the heap when we are forced to by the
semantics of the language, and try and be as fast about
it as we can.
 so, for starters, what is the
usual compiled program execution model? (this refers to other
static typed, strict execution, functions aren't first class languages.)

well, to simplify a lot, we use a stack of activation records
to represent each procedure's active data during invokation/execution.
this approach actually already natively supports passing
procedures in a downwards manner, as an argument, because when
the procedure is called within the lower environment, any bindings
which are free within the procedure will still be active on
the stack frame. C supports this usage of procedures through
the abstraction of function pointers. function pointers also
avoid the issues presented by closure implementations or other
implementations but is sacrifices a lot of the syntactic
brevity that functional language gain by avoiding being
so explicit.

why do i think this is even the slightest bit possible?
because the simply typed lambda calculus (which i will
call the lambda calculus throught this document, but
i really mean the simply typed version. the untyped version
is actually inherently unsound.) if we allow the underlying
primitive types to have the same behavior (i.e. the integer
type of the example lambda calculus and the integer type of C have
the same semantic behavior, and the same operations are defined
and have the same semantic behavior, because they are both talking
about the primitive integer type of the CPU and the arithmetic
operations defined by the CPU on the CPU integer type. i.e. both are
languages which are actually managing the mapping of symbols and
compositions of symbol to instructions and compositions of instructions)

then if we consider that both inspirational languages C and the lambda calculus.
are simply typed, strictly evaluating, pass arguments by-value, and support
(according to our conceits above) the same primitive types and
operations on those types. we can see how for certain cases of
term compositions the behavior is identical.

(so, truly it would be more accurate to say that we can consider
a simply typed, strictly evaluating, by value lambda calculus.
if this were a different language then we could instead consider a polymorphically
typed, lazily evaluating, by reference lambda calculus. but we are here
to express small programs that can largely stand on their own and
since C does a good job, we are going to consider a more ML style
functional language than a Haskell style functional language.
i'm not trying to make an actual argument that one is better than
the other for expression, my argument is that the C style language
is a simpler fundamental implementation that may be able to run with
less implicit overhead than if we define a large language with lots of
inter-operating runtime parts such that lazy evaluation and polymorphism
implies. i'm also not making the argument that a language such as ours
would be better without polymorphism like C, i'm saying that it's implementation
needs to be as lightweight as possible, with OOP style
virtual functions being a good benchmark. simple C style dispatch routines achieve
similar performance.
also also, something like the C++ template system exists alongside the language
and only adds to compile time, so would be a perfect fit.)


to proceed with the easy example, we start with the downwards case:
the syntax is largely not representative of the final syntax just yet.

procedure f1 (x: Int, y: Int) => x + y

procedure f2 (f: Int -> Int -> Int, g: Int, h: Int) => f g h

procedure main () => f2 f1 2 5

evaluating main pushes it's stack frame and then jumps
to the code representing the body, when we evaluate the
application we first attempt to evaluate each argument,
since each is an Object directly of the right type, nothing needs to be done,
then to evaluate we push f1's address into the first parameter,
we push two and five as the next two parameters, remember, by-value.
then we jump to the body of procedure f2.
then we can use the address passed through the first parameter,
(or the address held within the closure structure passed within
the first parameter) to jump to procedure f1, pushing the
arguments we received through positions 2, 3, into the first
and second arguments to applying the procedure passed through
the first argument. then we jump to the body of f1, perform
the correct operation, and return the resulting value to the
body of f2, which returns the value again to main, which
returns it to the OS.

there is no difference between this and the C code

typedef int (*funcp)(int, int);

int f1 (int x, int y)
{
  return x + y;
}

int f2 (funcp f, int g, int h)
{
  return f (g, h);
}

int main (void)
{
  return f2(f1, 2, 5);
}

which is some hint as to how we can implement this.

so to the contravening case:

procedure difficult () =>
  foo := 42;
  (\z:Nil => foo)

procedure main () =>
  closure := difficult ();
  print closure ()

by the previous execution model,
when difficult is invoked by main
the binding 'foo' and subsequently
the value 42 is stored on the stack
frame, then when the lambda is defined
in the current frame, the binding is alive
only until difficult returns. so,
when main goes to invoke 'closure' which
holds the lambda returned by difficult,
the reference to 'foo' is invalid, and
accessing it is undefined behavior.
(depends on the precise state of the
currently running system, which is not
knownable a-priori)

the first solution solves this by the fact
that activation records for procedures are
allocated on the heap, and thus the reference
to a variable in another procedures activation
record is always pointing to an alive and
valid binding. this approach is often combined
with a garbage collector so that activation
records can be cleaned up at some point after usage.

so the only real way to give the same semantics
is to follow suit and allocate space for closed
over values in the heap, and silently use those
bindings during evaluation of the returned procedure.
luckily, this is knowable from the source text, as
the names which cause this issue are by definition free
variables which are referenced within a locally defined
procedure. free variables which are bound within the
callers scope and not the global scope.

this is the basic insight for following the hybrid
stack/heap approach. essentially, closures are
not entirely necessary, but when they come in handy they
are invaluable, and the same for coroutines, and yet
to support these features we should not have to compromise
on the speed of our standard operation, namely
invoking monotonic procedures.
lets explore what i mean with an example,

procedure difficult () =>
  foo := 42;
  (\z:Nil => foo)

procedure main () =>
  closure := difficult ();
  print closure ()


can be imagined as

%closure-type = type opaque;

void difficult-lambda (i64* ret, i64* free-var0)
{
  // ret is a sret argument, which means it is the
  // called allocated return cell.
  // free-var0 is the free variable 'foo' captured
  // by the lambda definied in 'difficult'. free variables
  // are not written as part of the argument list, but
  // they are implicitly arguments for implementation.
  store free-var0 ret
}

void difficult (%closure-type ret)
{
  %foo = 42;
  %closure = {(void(i64*, i64*)*), {i64, [i64 x 2]}, {i64}}
  %closed-function = closure.0
  %type-desc = closure.1
  %closed-arguments = closure.2

  // put the address of the closure over function
  // into the structure
  store difficult-lambda closed-function

  // type-desc is an array that holds it's length,
  // and each element of the array helps to describe
  // the type of the closure
  // store the number of expected arguments to
  // build a procedure call in the first element of
  // type-desc, and the address of the closed argument
  // in the second element.
}

well, this might work, but the real problem that needs to
be solved is being able to call any particular closure
object (via an application term which provides more statically typed
arguments) via an opaque pointer, so we can pass different
closure structures to the same application point.
this has the implication that closures as return values
work the same way, they become opaque pointers from
the point of view of local storage.
thus we have two problems to solve for every closure objects.
you could say, we have two procedures to define,

application x y

where x is an opaque pointer to some closure
and y is some anon struct of values. and
the result is the result of application
of the underlying procedure.

append x y
where x is an opaque closure object,
and y is some anon struct of values, and
the result is a new opaque closure object
which is now storing y within it's closed
over values.

then, formally Application becomes a choice of
if we are storing a procedure as the result, (which
is storing a closure now remember) or if we can
apply the procedure and store the resulting procedure.

if we get this working, we should be able to test it
with the usual applications, testing out both
paths. but additionally, we can and should imagine
the scenario where one of the closed values is itself
another opaque ptr to a closure object. because then we
can imagine the argument list of a procedure object which
takes and applys procedure objects.

to my mind, the general approaches to implementing these
opaque objects fall into two general strategies i want to
try,
one: where we can cast the object to a lookuptable of sorts
     and then we can imagine application and apply being defined
     in terms of lookups, and a table append method.
     either it's an actual map, or a pseudo map made of a simpler type idk.

two: where we store sizes and void*'s and we implement what is generic
     using memcpy of the argument lists and new arguments. and
     we pass arguments in an untyped manner, but then within the
     procedure itself we typecast a big allocation to what is a
     anon struct of values and then we can extract arguments from
     this allocation.

either way we cannot avoid the heap allocation of the memory
the opaque pointers are referencing. this is where the
definition of the language rubs up against the stack allocation
strategy. C avoids calling malloc or free within the kernel entirely,
C++ does not, and i don't think Rust avoids it in the kernel either.
now, this strategy should be about as fast everytime as calling a
procedure through a heap allocated function pointer. which
does add overhead to every function call (that can't be optimized that is.)
what can be optimized? well, if we formally implement each procedure
that exists in a local scope/environment as an opaque ptr, then formally,
any procedure call would need to be a call from a stored ptr. however,
if we are simply calling a defined procedure, and not storing it locally,
then we can simply call that procedure. it is only when we explicitly
call a procedure with less than the required number of arguments, and
bind that temporary value to a name or pass it as a value that we -need-
a closure to represent that procedure within a memory cell.
(to this end, just like in C if you were to simply declare some value,
 and not bind it, or use it in an expression, the C compiler can simply
 ignore that data. any data that is not participant within the computation
 is simply not required, and by not having it there we save on spacetime.)

the second question, which is very much pertinent to our question of garbage
collection, do we need a garbage collector to implement a lambda calculus,
is, when can we safely free memory that our closure is pointing to?

since when we construct a closure, we must store it on the heap to achieve
our lifetime extension, we must use some implementation of malloc/free
to allocate our data on the heap, at runtime. and being responsible programmers
we are going to clean up our mess so to speak, and not just leave our
memory for the OS to clean up. so, when can we free a closure object?

well, lets recall when we construct closures, and when and how we
store closure objects.

a closure is built from an application of a function.

we know we need to call malloc at the point of application

// -- declaration
we define the procedure being closed around before we
define the closure.

// -- application


// -- consumption


----------------------------------------------------------------------------
I propose that for the first version we disallow
passing a procedure up the stack if it closes over a
free variable. if the inner procedure only uses names
which are passed as argument, then it is free to be
passed around to any environment, because it's behavior
is independent of the environment.
this should allow me to get a working system standing
up quicker, while still allowing me to upgrade the
system to fully support procedures later.

additionally a few more rules would allow even greater
flexibility, namely, every binding is immutable by default
and must be declared mutable explicitly by the programmer.
this allows the compiler to be assured that no assignments
will be done to this value, either directly or by reference.
this allows the compiler to store all immutable bindings
directly in the activation record. and when we implement
coroutines, and we save/restore the state of the stack
between two procedures, (up/down or horizontally), any
immutable binding is always the same value through the save/restore
process, even though there is (potentially) technically multiple by-value
copies sitting in the programs address space. to provide
support for a mutable variable within a coroutine, we must
store that value on the heap.
just as above with the case of a procedure closing over it's
surrounding environment and then referencing it at a later point
in execution, when it has potentially already been deallocated by
the defining scope returning, we need to copy each value referenced
into the heap, and a pointer kept in the structure representing the
by-value version of the procedure.

if we imagine a generator procedure which produces many different
closures, maybe each closing over a different value, but the
procedure is identical, what can happen to support this is
many closure objects are allocated at the return site, which
simply combine a function pointer to the same body,
and the pointer to the free variables which it references stored in the heap.
each of which is allocated at the time of creation of the closure.
for immutable values, a by-value copy suffices in all cases.
this only needs to happen when the inner procedure actually closes
over free data.
a closure can support assignment to an inner by-value
object in the same way that a regular procedure can support a regular
variable being assigned. allocation on the stack, and assignment
to the stack.

a closure cannot support assignment to a mutable free variable,
as the lifetime may end before the closure is invoked. so a
mutable free variable referenced within the closure must be stored
on the heap. this is precisely what we are closing over with the closure.

--------

- coroutines: throwing and returning control at will between two procedures,
effectively dictating the transfer of control between two
procedures whose lifetimes are now simultaneous.
(which raises the issue of, there is only one stack frame
active, with one set of bindings, at a time, how can we
maintain the bindings of two separate call stacks
in the same place at the same time? moreover, potentially
-any- two procedures defined within the program.)

a coroutine cannot support mutable values living on it's stack either.
because the only way to truly support coroutines is to maintain
multiple stacks. (e.g. execution environments) by way of copying
and restoring full or partial stack(s) to the heap.

if we want a coroutine to modify a variable within it's scope,
then the only way to accomplish this without extreme overhead
is to allocate the variable on the heap and make all named instances
read/write to the heap.
this in effect now means that all coroutines which
share visibility of the same mutable free variable
would share the exact same memory.

so, in effect a mutable variable can only be stored in the
activation record of a procedure if and only only if it
never appears free in a closure or coroutine. if we explicitly
pass the mutable variable as a argument, well we pass by-value.
so, either the callee can subsequently update a copy or
we pass a reference, (i suppose a mutable reference to maintain the
semantics), in which case the callee can modify the exact same object.
(except this time the programmer has to be explicit about the pass by
reference).

if all modifications to a mutable cell occur within it's defining
context, and it's value is no longer required after returning from
it's execution context, then that variable is free to be stored on
the stack. (I don't know how answerable those questions are in a
general sense though.)
common examples are index variables for iterating through an
array imperatively.

for (int i = 0; i < length; i++)
{ array[i] = func(array[i]); }

this integer (i) can absolutely be stored on the stack frame of
it's enclosing scope, because we only ever use it as a value within
it's defining context, in fact all modifications to this variable are
supportable with the data stored on the stack as well, and this
is the implementation strategy of C.
even if func itself is a closure around some data, i is not
participating in that discussion, because it is not used by
func in any way. even if we passed i directly we still would
have no issues, because i would be passed by-value to func.
which would retain at most a local copy. (and unless marked
as mutable in the argument list, wouldn't be writable.)
and if we pass a reference to i such that func could modify
i directly, i still think it's okay, because i is a valid memory
location, alive within the stack frame for the entire execution
of func, by definition the body of the for loop encompases this
entire call/return sequence for func, so unless it exits abnormally,
we can expect to return to this point of execution. so (i) can be
written to at any point within func, and if func calls a procedure
which takes i by reference again, the same argument holds. we expect that
the body of func itself encompases the call/return sequence for
the inner call. and as such (i) is alive on the stack for the entire
sequence. the issue comes when we pass the reference as the result
value of the procedure. if we are passing a reference to stack
allocated memory we cannot pass it out of the enclosing scope.
because the memory is deallocated once we leave the scope,
the reference is invalid as soon as we actually exit the scope.


it is only when two conditions are broken that we are forced into
allocating memory on the heap, when the lifetime of the closure in
question outlives it's defining scope, and the closure itself
contains a mutable free variable. (immutable variables can be handled by-value)
this mutable free variable must now be allocated on the heap
and a reference to this stored within the closure. i think it makes
sense that if the defining context of the closure contains the mutable free
variable, we capture it by value onto the heap, then when the closure
attempts to write to this mutable value, it would be a separate mutable
value from a closure that was created at a later point in execution.
this provides essentially the same by-value semantics of procedure calls
in C, and as such should make sense to anyone used to by-value semantics.
i guess if we bind a free variable that is itself a reference
to some memory on the heap we can achieve those semantics,
because the by-value copies of the reference would achieve
the sharing across all instances, even though it is always
handled in the assembly as a by-value copy into the heap.
this does add another layer of indirection when accessing that
value however.

so a choice of, immutable by default makes sense here, as the
default style will not run into the above issues. only when
the programmer explicitly asks for it, will they have to pay
the overhead. and with particular implementations we find no
overhead for usual monotonic procedure application.
nor do we find any overhead if the called procedure contains
no free variables whatsoever.

this discussion assumes that any time we are talking about
a closure, what we are talking about is an object that represents
a locally defined procedure, that captures memory declared within
it's defining local context and then this procedure object is returned out of
it's defining local context to be stored in an outer context,
either the calling context itself, or the calling context's calling context
or so on; and then the object is used within another application term,
which provides the final expected values at some later point.
the value that is held within the closure of
the procedure are the exact same values that would have been passed
to the procedure as arguments, were the previous application
to provide enough arguments that we must jump into and evaluate the
body of the procedure. thus the intermediate object, that represents the
procedure in a partially applied state can be formed by a pointer to
the procedure body, and a tuple of each of the previous arguments.
each time we partially apply the procedure, we form the new closure
by constructing a new tuple out of the old tuple plus the new value,
and we use the same function pointer. (or if interpreted we do strip
off each layer of the lambda, but the tuple now holds substitution pairs,
to be evaluated once every value is provided.) ((and if this works, we
should se no observably distinct behavior from evaluation. essentially
if we rewrite the interpreter to use this style of application, which is
slightly easier to translate into assembly using C style procedure
application, then nothing should change about the behavior of interpretation,
we should expect to see a by-value version of the simply typed Lambda
Calculus, regardless of which interpretation strategy we choose.))
also, also, given that we know a-priori which names are closed over
values at time of definition, we can emit instructions such that references
to the free names can be implemented in assembly as getting the correct
value out of the tuple stored in the heap, (and passed in as a hidden
first argument), and references to regular arguments can be done the
usual way, and so can references to local names. so can mutable references
to local names, and mutable values held within the tuple. (obviously these
work exactly like the by-value mutable values of C procedure calls.
so if you want the closure to point to some dynamic memory, then you can
do that. and then references to the name now pull a pointer out of the tuple.
we should disallow pointers to stack values from being returned, as this
reintroduces the exact semantic issue that we are trying to avoid with
closures in the first place.)

so, if you write a pure procedure, a pointer suffices in all calling
contexts, (along with the procedures type of course),




----


// okay, so we already assume that the Parse subroutine
// produces memory which we consume, this allows us to
// assign the pointers it returns into the Symboltable.
// I think we also need to make the same assumptions
// surrounding
// A) the error terms returned; in order to construct
//    useful error messages means constructing them
//    dynamically, this means that in the end, when we
//    consume the error, we must free it's description string.
//    all of them are constant strings now, however.
// B) the valid terms returned; each time we call Getype, it
//    constructs the tree which describes the type of the term
//    we passed in, this means we the caller are responsible for
//    it's memory. I suppose if we always allocate, and thus, are always
//    free to free memory that is known to be an intermediary value.
//    things that can be assigned dynamic memory that can be freed
//    in the allocating scope upon exit which maintains the discipline
//    of one free for every malloc. the only place memory is stored
//    and not immediately freed is the symoltable itself. and we
//
// 1) temporary values a.k.a. unnammed values.
//    this refers to storage that needs to be allocated
//    in order to compile the statement, but is not directly
//    requested by the programmer. most often used when a
//    expression is inserted where a procedure argument is
//    requested, the result of evaluation is stored in a
//    unnammed location before execution of the procedure.
//    but this scenario also occurs when dealing with long
//    operator expressions.
// 2) if some local variable gets dynamic memory, and then that
//    local variable falls out of scope. the dynamic memory is
//    absolutely lost. so we can free dynamic memory associated
//    with names that are never assigned to other local variables.
// 3) if a local variable is assigned dynamic memory, and then we
//    assign that memory to another local variable. this dynamic
//    memory's lifetime is tied to both, but for the purposes of
//    this algorithm, we can say that if both local variables fall
//    out of scope, this is the same as the single reference falling
//    out of scope, i.e. all references to the memory are lost, and
//    the memory leaks. so, assignment to other locals don't affect
//    the actual lifetime of the dynamic memory.
// 4) a case where dynamic memory lifetime is actually validly
//    extended is assignment to a variable located in a
//    higher scope, global or a lexically 'higher' procedure definition
//    the lifetime then becomes attached to that outer name, as well as
//    the inner name. this is a higher lexical lifetime.
   5) the last case I can think of that validly extends dynamic memory is
      when we assign that memory to the return value of the procedure.
      this is essentially a value that has it's lifetime tied to the immediate
      outer procedure frame. which is a higher dynamic lifetime.

if we observe a chain of assignments between procedures, such as
with the parsing subroutines, we can build up types of arbitrary
complexity according to the grammar rules. however, this is not a
replacement for being able to specify the layout of memory with types.
when we are considering a type like the Abstract syntax tree we are
considering two things simultaneously, the layout of each node, and
the layout of the tree as a whole. the layout of the inside of
the Ast is specified by the programmer, whereas the layout of
the dynamic form of any given tree is specified by the flow
of control throughout the execution of the program. a combination
of the lexical lifetimes and the dynamic lifetimes of the
set of parsing subroutines.

if we think about an inner procedure, we are thinking about
a regular procedure, except that we get to make a few extra
assumptions. given the procedures visibility is restricted to
the local scope exactly, we know that anytime we are in a call
to the inner procedure we must have reached it via a call to
the outer procedure. meaning we must have an active frame of the
outer procedure living on the stack immediately above us.
(this has a slight complication with recursion, either natural
or via Z. there is now some dynamic number (n) of frames between the current
recursive evaluation and the outer procedure frame.)

this means we can access the names bound within the outer frame
in the inner frame, given that we can assume the location of the
outer frame, relative to the known fixed sizes of both frames.

now, we may also capture by-reference, which also solves the recursion
issue, as each frame has a direct reference to a local variable.

once again here, we can note that a shared pointer to dynamic memory
has consistent semantics, whereas a pointer to mutable local memory
causes issues. so how about this. immutable names can be captured
implicitly. we are free to read a reference to some data which is guaranteed
to exist in all cases where we could reach a statement that would try to
read that data.

mutable dynamic memory can also be captured implicitly.
mutable stack memory can never be referenced outside of the defining
scope. we do not ever allow pointers which reference the stack to be returned
out of procedures. (they can be passed into procedures, but that makes the
rules more complex)
it might be simpler to force programmers into using dynamic
memory for all situations in which you want to pass the same memory into and
back out of a procedure call.

okay, so a pointer to immutable memory on the stack can be passed downwards.
as it's lifetime is tied to the stack frame that the memory was allocated
in.
a pointer to mutable memory can never point to the stack.
a pointer to mutable memory always points to the heap.

a mutable object may be stack allocated, but it may only
be modified within the local scope. and we can never return
the address of a name which is leaving the scope. (again,
unless we are talking about two names which point to dynamic
memory, or writing static memory into dynamic memory.)
or hell, reading dynamic memory into static memory is also fine
as long as we don't generate the address of the static memory
and return that.

so, we need mutable and immutable variables,
as well as mutable and immutable pointers.
pointers additionally need to distinguish between
a pointer to stack memory and a pointer into heap
memory.
and the code which tracks pointers and allocation
needs to be very careful to track violations of these
rules. at least what can be done at compile time.

a pointer to the stack is a valid pointer as long as the
memory it points to is stationary and constant.
if we need special rules for, say, alloca.
and we move stuff around the stack to allocated
and reallocate variables from the stack during
evaluation of a single procedure, any pointer to a
location which was moved would need to be updated with
the new location, this could be very complex very quickly.

a pointer to mutable memory on the stack is fairly safe in
a language with C's exact semantics, as procedure calls always
grow and shrink the stack in a regular way, however, it is this
authors intention to implement some form of parallelism at the
language level. at the time of writing this, the debate is between
threads and coroutines. threads have a C style calling api, so
it is easy to map them from C to Pink, whereas coroutines are a different
beast entirely. coroutines are sort of like a GOTO in that they allow
a program to execute code within different stack frames while
bypassing the usual calling semantics. this allows for a program to
implement things like event handlers (i.e. interrupts) in the syntax
of a higher level language. except that with true coroutines we also
allow a greater level of flexibility than simple interrupts, as
the programmer can yield to a new procedure, not just to exactly
where the procedure was called from.

now, if we want to support coroutines, we must be aware of how supporting
them interacts with the rest of the languages features.
if done right, coroutines will not add latency to evaluation of regular
procedure applications. what they will add latency too is coroutines,
and yeilding between the two.

imagine if you will two coroutines,

coroutine A (...)
{
...
yield B ...;
...
}

coroutine B (...)
{
...
yield A ...;
...
}

now, our main subroutine is still how we start evaluation, so
say we have one that looks like:

main (...)
{
  ...
  A ...;
  ...
  return 0;
}

this is a regular invokation of the coroutine, and as such involves
the call prolouge code before we can jump into the body of A.
pushing arguments onto the stack, etc. then when we are evaluating A
according to our usual means we encounter the yield statement,
this is where the special actions of the coroutine come in, in order to
fully save and then later restore the current state of execution of A
we need to save it's active registers into the heap, along with a copy
of the entire stack up to this point in evaluation. this therefore
would include the stack frame of the main procedure as well. (this is
so that the stack is in a valid state when we return back to A, and want
to carry out whatever actions it has left to do, one control is returned.
including but not limited to, reading data, writing data, invoking other
procedures, yielding to coroutines other than B, and returning execution
to the calling procedure.) so, once we save all of the active state of
coroutine A we then essentially do a procedure call into B, which then
does what it does until as we observe it yields control back to A,
now, when A is returned to, we do not jump back to the beginning of the
procedure as with a usual call, we jump back to the point at which
control was yielded. all of the data which was available up to the point
of yielding is restored into the active environment, and we resume
evaluation of A. this can continue in a loop, with control yielding
between two coroutines forever, or until some stop condition is reached,
or it can simply pass between coroutines until each is finished.
